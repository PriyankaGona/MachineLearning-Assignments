{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1_problem1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaGona/machinelearning-assignments/blob/master/hw1_problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iOVWXSn76h3o",
        "colab_type": "code",
        "outputId": "58bf1019-912b-4fc0-8581-67142d66571a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XHxLTjs2HpXF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert digits to binary values\n",
        "def to_categorical(y,nb_classes):\n",
        "  output = []\n",
        "  for i in y:\n",
        "    temp = np.zeros(nb_classes)\n",
        "    temp[i] = 1\n",
        "    output.append(temp)\n",
        "  output = np.array(output)\n",
        "  output = output.reshape(y.shape[0],nb_classes)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVKBzUkOHubx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# intitalizing weights and bias to zero\n",
        "def init(dim):\n",
        "    W = np.zeros(shape=(dim, num_classes))\n",
        "    b = 0\n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_cKvhSOqHyEJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sigmoid activation function\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgJkiHBeH2GH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MSE loss function\n",
        "def mean_square_loss(A, Y):\n",
        "    loss = np.mean((Y - A)**2)\n",
        "    loss = np.squeeze(loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IkSzdb8YH6pG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# backward propagation\n",
        "def backward_propagate(A, X, Y, batch_size):\n",
        "    m = batch_size\n",
        "    # gradient computation\n",
        "    dW = (1 / m) * np.dot(X, (2 * (A-Y) * A * (1-A)).T)\n",
        "    db = (1 / m) * np.sum(2 * (A-Y) * A * (1-A))\n",
        "\n",
        "    return dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5s40SwNKH9Rl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# forward porpagation\n",
        "def forward_propogate(W, b, X):\n",
        "    linear_transformation = np.dot(W.T, X) + b\n",
        "    output = sigmoid(linear_transformation)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-CMb7N0IIB2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mini-batch stochastic gradient descent\n",
        "def sgd(W, b, X, Y, epochs, learning_rate):\n",
        "\n",
        "    for j in range(epochs):\n",
        "        training_loss = []\n",
        "        for i in range(0, X.shape[1], batch_size):\n",
        "            x_train_mini = X.T[i:i+batch_size]\n",
        "            y_train_mini = Y.T[i:i+batch_size]\n",
        "            output = forward_propogate(W,b,x_train_mini.T)\n",
        "            loss = mean_square_loss(output,y_train_mini.T)\n",
        "            dW, db = backward_propagate(output,x_train_mini.T,y_train_mini.T,batch_size)\n",
        "\n",
        "            # gradient descent\n",
        "            W = W - learning_rate * dW\n",
        "            b = b - learning_rate * db\n",
        "\n",
        "            training_loss.append(loss)\n",
        "        epochLoss=sum(training_loss)/len(training_loss)\n",
        "        print(\"Epoch {}/{}\\t - loss : {}\".format(j+1,epochs,round(epochLoss,4)))\n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vchuFwj0IEoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculating accuracy of test data after training\n",
        "def predict(W, b, X):\n",
        "\n",
        "    m = X.shape[1]\n",
        "    y_pred = np.zeros((1, m))\n",
        "    W = W.reshape(X.shape[0], num_classes)\n",
        "    A = forward_propogate(W,b,X)\n",
        "\n",
        "    for i in range(A.shape[1]):\n",
        "        y_pred[0, i] = 1 if A[0, i] > 0.5 else 0\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XXRyvC6ZIKlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, epochs=50, learning_rate=0.1):\n",
        "\n",
        "    y_pred_train = Y_train\n",
        "    y_pred_test = Y_test\n",
        "\n",
        "    # shape of predict_y_train and predict_y_test is 60000,10 similar to that of y_train and y_test categorical values\n",
        "    y_pred_train = to_categorical(y_pred_train, 10)\n",
        "    y_pred_test = to_categorical(y_pred_test, 10)\n",
        "\n",
        "    for i in range(0, 10):\n",
        "        # set the digit to classify\n",
        "        classifier_digit = i\n",
        "        print(\"\\nClassifier: {}\".format(classifier_digit))\n",
        "        print(\"=======================================\")\n",
        "        # modify training labels to create single class classification\n",
        "        y_train_mod = np.array(Y_train)\n",
        "        y_train_mod = np.where(y_train_mod == classifier_digit, 1, 0)\n",
        "\n",
        "        y_test_mod = np.array(Y_test)\n",
        "        y_test_mod = np.where(y_test_mod == classifier_digit, 1, 0)\n",
        "\n",
        "        # core of the model\n",
        "        W, b = init(X_train.shape[0])\n",
        "        W, b = sgd(W, b, X_train, y_train_mod, epochs, learning_rate)\n",
        "\n",
        "        # predicting the values based on trained weights and bias values\n",
        "        Y_prediction_train = predict(W, b, X_train)\n",
        "        Y_prediction_test = predict(W, b, X_test)\n",
        "\n",
        "        # we will store ones in the corresponding to indices to create array to similar to categorical data of y_train\n",
        "        y_pred_train[:, [i]] = Y_prediction_train.T\n",
        "        y_pred_test[:, [i]] = Y_prediction_test.T\n",
        "\n",
        "        # train and test classifier accuracy for each digit\n",
        "        print(\"\\nAccuracy of classifer in training \" + str(i) + \" : {} %\".format(round((100 - np.mean(np.abs(Y_prediction_train - y_train_mod)) * 100),4)))\n",
        "        print(\"Accuracy of classifer in testing\" + str(i) + \" : {} %\".format(round((100 - np.mean(np.abs(Y_prediction_test - y_test_mod)) * 100),4)))\n",
        "        print(\"\\n\")\n",
        "\n",
        "    # coverting y_train from 60000,1 to 60000,10 i.e. to categorical\n",
        "    Y_train = to_categorical(Y_train, 10)\n",
        "    Y_test = to_categorical(Y_test, 10)\n",
        "\n",
        "    # overall test and train classifier accuracy of the network\n",
        "    print(\"Overall accuracy in Training: {} %\".format(round((100 - np.mean(np.abs(y_pred_train - Y_train)) * 100),4)))\n",
        "    print(\"Overall accuracy in Testing: {} %\".format(round((100 - np.mean(np.abs(y_pred_test - Y_test)) * 100),4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d952avvDN0_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3553
        },
        "outputId": "1f2297a6-f6ba-4236-84bd-a25ee9b21b09"
      },
      "cell_type": "code",
      "source": [
        "# variables\n",
        "batch_size = 32\n",
        "num_classes = 1\n",
        "epochs = 12\n",
        "\n",
        "# Image Dimensions of MNIST\n",
        "rows = 28\n",
        "cols = 28\n",
        "\n",
        "# loading MNIST dataset using keras\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# reshaping dataset\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]).T\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]).T\n",
        "\n",
        "# Normalization\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "\n",
        "model(x_train, y_train, x_test, y_test, epochs=12,learning_rate=0.01)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            "Classifier: 0\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0387\n",
            "Epoch 2/12\t - loss : 0.0197\n",
            "Epoch 3/12\t - loss : 0.0164\n",
            "Epoch 4/12\t - loss : 0.0147\n",
            "Epoch 5/12\t - loss : 0.0136\n",
            "Epoch 6/12\t - loss : 0.0129\n",
            "Epoch 7/12\t - loss : 0.0123\n",
            "Epoch 8/12\t - loss : 0.0118\n",
            "Epoch 9/12\t - loss : 0.0114\n",
            "Epoch 10/12\t - loss : 0.0111\n",
            "Epoch 11/12\t - loss : 0.0108\n",
            "Epoch 12/12\t - loss : 0.0106\n",
            "\n",
            "Accuracy of classifer in training 0 : 98.9017 %\n",
            "Accuracy of classifer in testing0 : 99.14 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 1\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.036\n",
            "Epoch 2/12\t - loss : 0.0182\n",
            "Epoch 3/12\t - loss : 0.0152\n",
            "Epoch 4/12\t - loss : 0.0137\n",
            "Epoch 5/12\t - loss : 0.0128\n",
            "Epoch 6/12\t - loss : 0.0122\n",
            "Epoch 7/12\t - loss : 0.0117\n",
            "Epoch 8/12\t - loss : 0.0113\n",
            "Epoch 9/12\t - loss : 0.011\n",
            "Epoch 10/12\t - loss : 0.0107\n",
            "Epoch 11/12\t - loss : 0.0105\n",
            "Epoch 12/12\t - loss : 0.0103\n",
            "\n",
            "Accuracy of classifer in training 1 : 98.9 %\n",
            "Accuracy of classifer in testing1 : 99.19 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 2\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0605\n",
            "Epoch 2/12\t - loss : 0.0359\n",
            "Epoch 3/12\t - loss : 0.0307\n",
            "Epoch 4/12\t - loss : 0.0281\n",
            "Epoch 5/12\t - loss : 0.0265\n",
            "Epoch 6/12\t - loss : 0.0253\n",
            "Epoch 7/12\t - loss : 0.0244\n",
            "Epoch 8/12\t - loss : 0.0237\n",
            "Epoch 9/12\t - loss : 0.0231\n",
            "Epoch 10/12\t - loss : 0.0226\n",
            "Epoch 11/12\t - loss : 0.0222\n",
            "Epoch 12/12\t - loss : 0.0219\n",
            "\n",
            "Accuracy of classifer in training 2 : 97.545 %\n",
            "Accuracy of classifer in testing2 : 97.65 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 3\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0618\n",
            "Epoch 2/12\t - loss : 0.0392\n",
            "Epoch 3/12\t - loss : 0.0344\n",
            "Epoch 4/12\t - loss : 0.0319\n",
            "Epoch 5/12\t - loss : 0.0303\n",
            "Epoch 6/12\t - loss : 0.0292\n",
            "Epoch 7/12\t - loss : 0.0284\n",
            "Epoch 8/12\t - loss : 0.0277\n",
            "Epoch 9/12\t - loss : 0.0271\n",
            "Epoch 10/12\t - loss : 0.0266\n",
            "Epoch 11/12\t - loss : 0.0262\n",
            "Epoch 12/12\t - loss : 0.0259\n",
            "\n",
            "Accuracy of classifer in training 3 : 97.0317 %\n",
            "Accuracy of classifer in testing3 : 97.32 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 4\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0558\n",
            "Epoch 2/12\t - loss : 0.0334\n",
            "Epoch 3/12\t - loss : 0.0281\n",
            "Epoch 4/12\t - loss : 0.0255\n",
            "Epoch 5/12\t - loss : 0.0238\n",
            "Epoch 6/12\t - loss : 0.0226\n",
            "Epoch 7/12\t - loss : 0.0217\n",
            "Epoch 8/12\t - loss : 0.021\n",
            "Epoch 9/12\t - loss : 0.0204\n",
            "Epoch 10/12\t - loss : 0.0199\n",
            "Epoch 11/12\t - loss : 0.0195\n",
            "Epoch 12/12\t - loss : 0.0192\n",
            "\n",
            "Accuracy of classifer in training 4 : 97.9583 %\n",
            "Accuracy of classifer in testing4 : 97.74 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 5\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0692\n",
            "Epoch 2/12\t - loss : 0.0482\n",
            "Epoch 3/12\t - loss : 0.0415\n",
            "Epoch 4/12\t - loss : 0.0381\n",
            "Epoch 5/12\t - loss : 0.0359\n",
            "Epoch 6/12\t - loss : 0.0344\n",
            "Epoch 7/12\t - loss : 0.0332\n",
            "Epoch 8/12\t - loss : 0.0323\n",
            "Epoch 9/12\t - loss : 0.0315\n",
            "Epoch 10/12\t - loss : 0.0309\n",
            "Epoch 11/12\t - loss : 0.0303\n",
            "Epoch 12/12\t - loss : 0.0298\n",
            "\n",
            "Accuracy of classifer in training 5 : 96.7017 %\n",
            "Accuracy of classifer in testing5 : 96.87 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 6\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0482\n",
            "Epoch 2/12\t - loss : 0.0245\n",
            "Epoch 3/12\t - loss : 0.0204\n",
            "Epoch 4/12\t - loss : 0.0185\n",
            "Epoch 5/12\t - loss : 0.0173\n",
            "Epoch 6/12\t - loss : 0.0164\n",
            "Epoch 7/12\t - loss : 0.0158\n",
            "Epoch 8/12\t - loss : 0.0153\n",
            "Epoch 9/12\t - loss : 0.0149\n",
            "Epoch 10/12\t - loss : 0.0146\n",
            "Epoch 11/12\t - loss : 0.0143\n",
            "Epoch 12/12\t - loss : 0.014\n",
            "\n",
            "Accuracy of classifer in training 6 : 98.4633 %\n",
            "Accuracy of classifer in testing6 : 98.34 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 7\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0463\n",
            "Epoch 2/12\t - loss : 0.0256\n",
            "Epoch 3/12\t - loss : 0.0221\n",
            "Epoch 4/12\t - loss : 0.0204\n",
            "Epoch 5/12\t - loss : 0.0193\n",
            "Epoch 6/12\t - loss : 0.0185\n",
            "Epoch 7/12\t - loss : 0.0179\n",
            "Epoch 8/12\t - loss : 0.0174\n",
            "Epoch 9/12\t - loss : 0.0171\n",
            "Epoch 10/12\t - loss : 0.0167\n",
            "Epoch 11/12\t - loss : 0.0165\n",
            "Epoch 12/12\t - loss : 0.0162\n",
            "\n",
            "Accuracy of classifer in training 7 : 98.1567 %\n",
            "Accuracy of classifer in testing7 : 98.26 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 8\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.086\n",
            "Epoch 2/12\t - loss : 0.0626\n",
            "Epoch 3/12\t - loss : 0.0549\n",
            "Epoch 4/12\t - loss : 0.0511\n",
            "Epoch 5/12\t - loss : 0.0487\n",
            "Epoch 6/12\t - loss : 0.047\n",
            "Epoch 7/12\t - loss : 0.0457\n",
            "Epoch 8/12\t - loss : 0.0447\n",
            "Epoch 9/12\t - loss : 0.0438\n",
            "Epoch 10/12\t - loss : 0.043\n",
            "Epoch 11/12\t - loss : 0.0423\n",
            "Epoch 12/12\t - loss : 0.0418\n",
            "\n",
            "Accuracy of classifer in training 8 : 95.1067 %\n",
            "Accuracy of classifer in testing8 : 95.01 %\n",
            "\n",
            "\n",
            "\n",
            "Classifier: 9\n",
            "=======================================\n",
            "Epoch 1/12\t - loss : 0.0734\n",
            "Epoch 2/12\t - loss : 0.0532\n",
            "Epoch 3/12\t - loss : 0.0467\n",
            "Epoch 4/12\t - loss : 0.0432\n",
            "Epoch 5/12\t - loss : 0.0409\n",
            "Epoch 6/12\t - loss : 0.0393\n",
            "Epoch 7/12\t - loss : 0.0381\n",
            "Epoch 8/12\t - loss : 0.0371\n",
            "Epoch 9/12\t - loss : 0.0363\n",
            "Epoch 10/12\t - loss : 0.0356\n",
            "Epoch 11/12\t - loss : 0.0351\n",
            "Epoch 12/12\t - loss : 0.0346\n",
            "\n",
            "Accuracy of classifer in training 9 : 95.84 %\n",
            "Accuracy of classifer in testing9 : 96.05 %\n",
            "\n",
            "\n",
            "Overall accuracy in Training: 97.4605 %\n",
            "Overall accuracy in Testing: 97.557 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d0WBbpGJINIj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}